from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List
from langchain_google_genai import ChatGoogleGenerativeAI
from dotenv import load_dotenv
import os
import uvicorn
from langchain.agents import Tool, ZeroShotAgent, AgentExecutor
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from ingest import create_cloud_sql_database_connection, get_embeddings, get_vector_store
from retrieve import get_relevant_documents
from config import TABLE_NAME
import re

# Load environment variables
load_dotenv()
API_KEY = os.getenv('API_KEY')
if not API_KEY:
    raise ValueError("API_KEY is missing. Please set it in the environment variables.")

SYSTEM_PROMPT = """
Tu es AstraMed, un assistant virtuel sp√©cialis√© dans l'information m√©dicale. Voici tes objectifs et tes r√®gles :
1. Tu n'es pas un m√©decin et tu ne peux pas remplacer un avis m√©dical professionnel.
2. Tes r√©ponses doivent rester professionnelles, claires et factuelles.
3. Si tu ne connais pas la r√©ponse ou si l'information est incertaine, indique-le de mani√®re transparente.
4. Utilise un ton poli et empathique.
5. Invite toujours l'utilisateur √† consulter un professionnel de sant√© pour un diagnostic ou un traitement pr√©cis.
6. Tes r√©ponses peuvent contenir des explications m√©dicales simplifi√©es, mais veille √† ne pas fournir de diagnostic formel.
"""

app = FastAPI(
    title="AstraMed API",
    description="API pour AstraMed via Agent LangChain",
    version="1.0.0"
)

engine = create_cloud_sql_database_connection()
embedding = get_embeddings()
vector_store = get_vector_store(engine, TABLE_NAME, embedding)

class UserInput(BaseModel):
    question: str
    temperature: float
    language: str
    similarity_threshold: float
    session_id: str = ""

class FeedbackInput(BaseModel):
    session_id: str
    question: str
    rating: int  # 1 pour üëç, 0 pour üëé
    comments: str = ""

# Function to parse agent output more robustly
def parse_agent_output(agent_output: str) -> dict:
    # Find all observations
    observations = re.findall(r"Observation:\s*(.+?)(?=\n\w+:|$)", agent_output, re.DOTALL)
    
    # Determine response type
    is_general_response = "general_response" in agent_output
    is_medical_response = "search_medical_docs" in agent_output
    
    # If observations exist, use the last one
    if observations:
        generated_response = observations[-1].strip()
        
        # Determine response type
        if is_general_response:
            response_type = "general"
        elif is_medical_response:
            response_type = "medical"
            # Append standard medical advice
            generated_response += " Consultez un professionnel de sant√©."
        else:
            response_type = "general"
        
        return {
            "type": response_type,
            "generated_response": generated_response
        }
    
    # Fallback parsing for Final Answer format
    match = re.search(r"Final Answer:\s*\[TYPE:\s*(general|medical)\]\s*(.+)", agent_output, re.DOTALL)
    if match:
        response_type = match.group(1)
        generated_response = match.group(2).strip()
        
        # Append medical advice for medical responses
        if response_type == "medical":
            generated_response += " Consultez un professionnel de sant√©."
        
        return {
            "type": response_type,
            "generated_response": generated_response
        }
    
    # Alternative observation parsing
    observation_match = re.search(r"Observation:\s*(.+?)(?:\nThought:|$)", agent_output, re.DOTALL)
    if observation_match:
        generated_response = observation_match.group(1).strip()
        response_type = "general" if is_general_response else "medical"
        
        # Append medical advice for medical responses
        if response_type == "medical":
            generated_response += " Consultez un professionnel de sant√©."
        
        return {
            "type": response_type,
            "generated_response": generated_response
        }
    
    # Fallback parsing for lines
    lines = [line.strip() for line in agent_output.splitlines() if line.strip()]
    if lines:
        # Take the last meaningful line
        generated_response = lines[-1]
        response_type = "general" if is_general_response else "medical"
        
        # Append medical advice for medical responses
        if response_type == "medical":
            generated_response += " Consultez un professionnel de sant√©."
        
        return {
            "type": response_type,
            "generated_response": generated_response
        }
    
    # Complete fallback
    return {
        "type": "unknown",
        "generated_response": "Erreur lors de la g√©n√©ration de la r√©ponse."
    }

# Bonus function to extract sources for medical responses
def extract_medical_sources(agent_output: str) -> List[dict]:
    # Regex to extract sources with their details
    source_pattern = r"üè• *Source \d+:\s*(\w+)\s*\(Similarit√©:\s*([\d.]+)\)\nüîπ *R√©ponse \d+ *:*\s*(.+?)(?=\nüè• *Source|\n\n|$)"
    
    sources = []
    for match in re.finditer(source_pattern, agent_output, re.DOTALL | re.IGNORECASE):
        sources.append({
            "source": match.group(1),
            "similarity": float(match.group(2)),
            "content": match.group(3).strip()
        })
    
    return sources

# Function to search medical documents
def search_medical_docs(query: str, similarity_threshold: float) -> tuple[str, List[dict]]:
    docs = get_relevant_documents(query, vector_store, similarity_threshold)
    print(f"[DEBUG] Documents trouv√©s dansGAR vector_store : {len(docs)}")
    if not docs:
        return "Aucune source pertinente trouv√©e.", []
    
    top_docs = []
    for doc in docs[:3]:
        ans = doc.metadata.get("answer", "R√©ponse non disponible.")
        src = doc.metadata.get("source", "Inconnue")
        scr = doc.metadata.get("score", 0.0)
        top_docs.append({
            "message": ans,
            "metadata": {
                "source": src,
                "similarity_score": scr
            }
        })
    print(f"[DEBUG] Top 3 documents : {top_docs}")
    top_docs_str = "\n".join([f"{doc['message']}" for doc in top_docs if doc["message"] != "R√©ponse non disponible."])
    return top_docs_str, top_docs

# Function for general responses
def general_response(query: str) -> str:
    llm = ChatGoogleGenerativeAI(
        model="gemini-1.5-pro",
        google_api_key=API_KEY,
        temperature=0.3,
        verbose=True
    )
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": query}
    ]
    response = llm.invoke(messages)
    return response.content

# Initialize the language model
def get_llm(temperature: float = 0.0) -> ChatGoogleGenerativeAI:
    return ChatGoogleGenerativeAI(
        model="gemini-1.5-pro",
        google_api_key=API_KEY,
        temperature=temperature,
        verbose=True
    )

@app.post("/feedback")
async def feedback(feedback: FeedbackInput):
    try:
        print(f"üìä Feedback re√ßu : {feedback.dict()}")
        return {"message": "Feedback enregistr√© avec succ√®s."}
    except Exception as e:
        print(f"‚ùå Erreur de feedback: {str(e)}")
        raise HTTPException(status_code=500, detail="Erreur lors de l'enregistrement du feedback")

@app.get("/")
async def root():
    return {"status": "AstraMed API is running"}

@app.post("/answer")
async def answer(user_input: UserInput):
    try:
        # Define tools
        tool_search = Tool(
            name="search_medical_docs",
            func=lambda q: search_medical_docs(q, user_input.similarity_threshold)[0],
            description="Recherche dans la base de documents m√©dicaux. √Ä utiliser uniquement pour les questions m√©dicales sp√©cifiques (sympt√¥mes, diagnostics, traitements)."
        )
        tool_general = Tool(
            name="general_response",
            func=general_response,
            description="R√©pond aux questions g√©n√©rales ou salutations en utilisant le prompt syst√®me."
        )

        # Language model with adjustable temperature
        llm = get_llm(temperature=user_input.temperature)

        # Updated agent prompt with clear format and examples
        agent_prompt = """
Tu es AstraMed, un assistant m√©dical sp√©cialis√©. L'entr√©e fournie est de la forme :
[question]
Langue de r√©ponse : [language]

Suis ces √©tapes strictement :
1. Analyse uniquement la partie [question] pour d√©terminer si elle est :
   - M√©dicale : Sympt√¥mes, maladies, traitements (ex: 'mal de t√™te', 'diab√®te')
   - G√©n√©rale : Salutations, questions personnelles, remerciements (ex: 'bonjour', 'merci')
2. Si la question est G√âN√âRALE :
   - Utilise l'outil general_response avec [question] uniquement.
   - R√©ponds dans la langue sp√©cifi√©e par [language].
   - Formate ta r√©ponse finale comme suit : "Final Answer: [TYPE: general] [r√©ponse]"
3. Si la question est M√âDICALE :
   - Utilise l'outil search_medical_docs avec [question] uniquement.
   - Int√®gre les sources dans ta r√©ponse avec la mention "[Source]".
   - Ajoute √† la fin : "Consultez un professionnel de sant√©."
   - R√©ponds dans la langue sp√©cifi√©e par [language].
   - Formate ta r√©ponse finale comme suit : "Final Answer: [TYPE: medical] [r√©ponse]"

Exemples de r√©ponses attendues :
- Pour "bonjour" :
  Thought: La question est une salutation, donc de type G√âN√âRALE.
  Action: general_response
  Action Input: bonjour
  Observation: Bonjour ! Je suis AstraMed, votre assistant virtuel d'information m√©dicale. Comment puis-je vous aider aujourd'hui ? ...
  Final Answer: [TYPE: general] Bonjour ! Je suis AstraMed, votre assistant virtuel d'information m√©dicale. Comment puis-je vous aider aujourd'hui ? N'oubliez pas que je ne peux pas donner d'avis m√©dical.
- Pour "quels sont les sympt√¥mes du diab√®te" :
  Thought: La question concerne une maladie, donc de type M√âDICALE.
  Action: search_medical_docs
  Action Input: quels sont les sympt√¥mes du diab√®te
  Observation: Les sympt√¥mes du diab√®te incluent ...
  Final Answer: [TYPE: medical] Les sympt√¥mes du diab√®te incluent ... [Source]. Consultez un professionnel de sant√©.

Entr√©e compl√®te : {input}
{agent_scratchpad}
"""

        # Configure prompt and LLM chain
        prompt_template = PromptTemplate(
            input_variables=["input", "agent_scratchpad"],
            template=agent_prompt
        )
        llm_chain = LLMChain(llm=llm, prompt=prompt_template)

        # Initialize agent with iteration limit
        agent_instance = ZeroShotAgent(
            llm_chain=llm_chain,
            tools=[tool_search, tool_general],
            verbose=True
        )
        agent_executor = AgentExecutor.from_agent_and_tools(
            agent=agent_instance,
            tools=[tool_search, tool_general],
            verbose=True,
            max_iterations=1  # Limit to one iteration
        )

        # Format user input
        user_query = f"{user_input.question}\nLangue de r√©ponse : {user_input.language}"

        # Run the agent
        agent_output = agent_executor.run(user_query)
        print(f"[DEBUG] Agent output raw: {agent_output}")

        # Parse the agent's response
        parsed_response = parse_agent_output(agent_output)
        response_type = parsed_response["type"]
        generated_response = parsed_response["generated_response"]

        # Retrieve relevant documents for medical responses
        if response_type == "medical":
            _, relevant_docs = search_medical_docs(user_input.question, user_input.similarity_threshold)
        else:
            relevant_docs = []

        print(f"[AstraMed] R√©ponse finale: {response_type} - {generated_response}")
        print(f"[DEBUG] R√©ponse JSON : {{'type': '{response_type}', 'generated_response': '{generated_response}', 'answers': {relevant_docs}}}")

        # Return the final response
        return {
            "type": response_type,
            "generated_response": generated_response,
            "answers": relevant_docs if response_type == "medical" else []
        }
    except Exception as e:
        print(f"‚ùå Erreur d√©taill√©e: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Erreur lors du traitement : {str(e)}")

if __name__ == "__main__":
    uvicorn.run(app, host="127.0.0.1", port=8181)
